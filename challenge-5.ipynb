{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2tw01le53fJ"
      },
      "source": [
        "# Challenge 5 - RNNs\n",
        "\n",
        "Welcome to challenge #5!\n",
        "\n",
        "In this challenge, you will implement a simple RNN classifier using an LSTM cell for sentiment analysis on the YelpReviewPolarity dataset (a binary sentiment classification dataset).\n",
        "\n",
        "Your model should include:\n",
        "- An **Embedding** layer (with a specified `padding_idx`)\n",
        "- An **LSTM** layer (with `batch_first=True`)\n",
        "- A **Fully Connected (fc)** layer to map the final hidden state to the output\n",
        "- A **Sigmoid** activation to produce a probability between 0 and 1\n",
        "\n",
        "Your tasks are:\n",
        "\n",
        "1. **Data Preprocessing & DataLoader Setup** (2 points):  \n",
        "   Import the YelpReviewPolarity dataset, tokenize the text, build a vocabulary, and create a DataLoader to supply batches to your model.\n",
        "\n",
        "2. **RNNClassifier** (2 points):  \n",
        "   Implement a class that builds and returns the RNN classifier model using the parameters provided.\n",
        "\n",
        "3. **Training and evaluating the model** (2 points):  \n",
        "   Implement a function that takes your model and trains it over a number of epochs and then tests it with sample yelp reviews.\n",
        "\n",
        "4. **Q&A Section** (3 points total, 1 point each):  \n",
        "   Answer three questions (in markdown) about your implementation and key concepts.\n",
        "\n",
        "When you are finished, the provided pytest tests at the end of this notebook will automatically evaluate your code.\n",
        "\n",
        "\n",
        "## Important Note on Environment:\n",
        "This challenge will <span style=\"color: red\">not work properly on Codespaces</span> because of the lack of GPU and pytorch support (at least I haven't figured out the setup yet). So for this challenge, you will open your repository's notebook in Google Collab and continue. You can do so by clicking the \"Open in Collab\" badge below and opening this notebook from your repository there.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "After completing the code part, please make sure to run the TESTING section of this notebook for the test cases. Again, the pytest on Github will fail. I shall manually enter your grades without the help of the autograder for this challenge referring to the test section at the end."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-yV17Adiv5T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YWLjrcJid9O"
      },
      "source": [
        "## Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuyXADf0id9O",
        "outputId": "90abd6cf-c143-453e-c411-6cfbfeaa4da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-19 14:59:49--  https://drive.usercontent.google.com/download?id=0Bz8a_Dbh9QhbNUpYQ2N3SGlFaDg&export=download&authuser=0&confirm=t&uuid=08839d6e-0170-44f8-a1c1-2f829c484617&at=AIrpjvOJpeXNKY4yGqP9mw6bXpQS:1739966900676\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.217.194.132, 2404:6800:4003:c04::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.217.194.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 166373322 (159M) [application/octet-stream]\n",
            "Saving to: ‘yelp_review_polarity_csv.tar’\n",
            "\n",
            "yelp_review_polarit 100%[===================>] 158.67M   164MB/s    in 1.0s    \n",
            "\n",
            "2025-02-19 14:59:52 (164 MB/s) - ‘yelp_review_polarity_csv.tar’ saved [166373322/166373322]\n",
            "\n",
            "yelp_review_polarity_csv/\n",
            "yelp_review_polarity_csv/readme.txt\n",
            "yelp_review_polarity_csv/test.csv\n",
            "yelp_review_polarity_csv/train.csv\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.11/dist-packages (0.6.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: portalocker==2.7.0 in /usr/local/lib/python3.11/dist-packages (2.7.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1) (2.32.3)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1) (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchdata==0.6.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchdata==0.6.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchdata==0.6.1) (3.31.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchdata==0.6.1) (18.1.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.6.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.6.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.6.1) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->torchdata==0.6.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->torchdata==0.6.1) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Downloading the yelp review dataset\n",
        "!wget \"https://drive.usercontent.google.com/download?id=0Bz8a_Dbh9QhbNUpYQ2N3SGlFaDg&export=download&authuser=0&confirm=t&uuid=08839d6e-0170-44f8-a1c1-2f829c484617&at=AIrpjvOJpeXNKY4yGqP9mw6bXpQS:1739966900676\" -O yelp_review_polarity_csv.tar\n",
        "\n",
        "# Extracting the dataset\n",
        "!tar -xvf yelp_review_polarity_csv.tar\n",
        "\n",
        "# Downloading python package dependencies\n",
        "!pip install torchdata==0.6.1 torchtext portalocker==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwlMI-Amid9P",
        "outputId": "d826e8f8-598d-44a4-beeb-1dbc4426f769"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ac37454a2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.datasets import YelpReviewPolarity\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torchtext\n",
        "import csv\n",
        "\n",
        "# Set random seed for reproducibility.\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPSP2Mt8id9P"
      },
      "source": [
        "## Task 1: Data Preprocessing (2 points)\n",
        "\n",
        "Note: the YelpReviewPolarity dataset label includes\n",
        "- 1 : Negative polarity.\n",
        "- 2 : Positive polarity.\n",
        "\n",
        "Refer the [pytorch docs](https://pytorch.org/text/0.8.1/datasets.html#yelpreviewpolarity) for the dataset for more info.\n",
        "\n",
        "The below code cell downloads the dataset and loads it for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brVO1D-nid9P",
        "outputId": "14a0e72e-5748-4ee0-fe18-b105735a8f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 50000\n",
            "Number of testing examples: 38000\n"
          ]
        }
      ],
      "source": [
        "def load_local_yelp_list(train_csv_path, test_csv_path, has_header=True, sample_size=50000):\n",
        "    \"\"\"\n",
        "    Reads the local train.csv and test.csv for Yelp Review Polarity\n",
        "    and returns two lists: train_list, test_list,\n",
        "    where each element is (label, text).\n",
        "    label is int (1 or 2), text is the review string.\n",
        "    \"\"\"\n",
        "    train_list = []\n",
        "    with open(train_csv_path, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.reader(f)\n",
        "        if has_header:\n",
        "            next(reader, None)  # skip the header row\n",
        "        for row in reader:\n",
        "            if len(train_list) >= sample_size:\n",
        "                break\n",
        "            label_str, text = row\n",
        "            label = int(label_str)\n",
        "            train_list.append((label, text))\n",
        "\n",
        "    test_list = []\n",
        "    with open(test_csv_path, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.reader(f)\n",
        "        if has_header:\n",
        "            next(reader, None)\n",
        "        for row in reader:\n",
        "            label_str, text = row\n",
        "            label = int(label_str)\n",
        "            test_list.append((label, text))\n",
        "\n",
        "    return train_list, test_list\n",
        "\n",
        "train_list, test_list = load_local_yelp_list('./yelp_review_polarity_csv/train.csv', './yelp_review_polarity_csv/test.csv', has_header=False)\n",
        "print(f\"Number of training examples: {len(train_list)}\")\n",
        "print(f\"Number of testing examples: {len(test_list)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eHldKrR3id9Q"
      },
      "outputs": [],
      "source": [
        "# TODO: Define a tokenizer using torchtext's basic_english tokenizer.\n",
        "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\", language='en')\n",
        "\n",
        "# TODO: Write a function 'yield_tokens' that takes the dataset iterator and yields tokens.\n",
        "def yield_tokens(data_iter):\n",
        "    # Replace with your code: iterate over data_iter and yield tokens for each text.\n",
        "    for text in data_iter:\n",
        "      yield tokenizer(text[1])\n",
        "\n",
        "# TODO: Print the first datapoint from your train list\n",
        "\n",
        "\n",
        "# TODO: Build the vocabulary using 'build_vocab_from_iterator' with special tokens '<unk>' and '<pad>'.\n",
        "# Set the default index for unknown tokens to the index of '<unk>'.\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_list), specials=['<unk>', '<pad>'], special_first=True)\n",
        "vocab.set_default_index(0)\n",
        "# TODO: Define a text pipeline function that converts a text string into a list of token IDs using the vocabulary.\n",
        "def text_pipeline(text):\n",
        "    # Replace with your code.\n",
        "    return vocab.lookup_indices(tokenizer(text))\n",
        "\n",
        "# TODO: Define a label pipeline function that converts the label (as a string) into an integer (e.g., 1 for positive, 0 for negative).\n",
        "def label_pipeline(label):\n",
        "    if label == 2:\n",
        "        return 1\n",
        "    elif label == 1:\n",
        "        return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XUW7xDkzid9Q"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Create a custom Dataset and DataLoader\n",
        "# -------------------------\n",
        "class YelpDataset(Dataset):\n",
        "    def __init__(self, data_iter):\n",
        "        # TODO: Store the data and process it if necessary.\n",
        "        self.data = [(text_pipeline(text[1]), label_pipeline(text[0])) for text in data_iter]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # TODO: Return the processed (text_tensor, label) tuple for index idx.\n",
        "        text_tensor, label = self.data[idx]\n",
        "        return text_tensor, label\n",
        "\n",
        "\n",
        "# TODO: Create a collate function that pads sequences in a batch.\n",
        "def collate_batch(batch):\n",
        "    # Replace with your code.\n",
        "    text, label = zip(*batch)\n",
        "    text = pad_sequence(text, batch_first=True, padding_value=vocab['<pad>'])\n",
        "    return text, torch.tensor(label)\n",
        "\n",
        "\n",
        "# TODO: Create a DataLoader for the training data.\n",
        "batch_size = 32\n",
        "train_dataset = YelpDataset(train_list)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbOTAFdzid9Q"
      },
      "source": [
        "## Task 2: Build the RNN Classifier (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ASUNJBp_id9Q"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement the RNNClassifier class with no implementation provided.\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size: int, embed_dim: int, hidden_dim: int, output_dim: int, num_layers: int, padding_idx: int):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        # TODO: Create an Embedding layer.\n",
        "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim, padding_idx=padding_idx)  # Your code here.\n",
        "        # TODO: Create an LSTM layer (batch_first=True).\n",
        "        self.lstm = torch.nn.LSTM(batch_first=True, num_layers=num_layers, input_size=vocab_size, hidden_size=hidden_dim)  # Your code here.\n",
        "        # TODO: Create a fully connected layer mapping hidden_dim to output_dim.\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)  # Your code here.\n",
        "        # TODO: Create a Sigmoid activation.\n",
        "        self.sigmoid = torch.nn.Sigmoid()  # Your code here.\n",
        "\n",
        "def forward(self, text):\n",
        "    # text: [batch_size, seq_length]\n",
        "    # Convert token IDs into embeddings\n",
        "    embedded = self.embedding(text)  # [batch_size, seq_length, embedding_dim]\n",
        "\n",
        "    output, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "    if self.lstm.bidirectional:\n",
        "        hidden_last = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "    else:\n",
        "        hidden_last = hidden[-1,:,:]\n",
        "\n",
        "\n",
        "    logits = self.fc(hidden_last)\n",
        "\n",
        "    return torch.sigmoid(logits).squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93gpGnKqid9Q"
      },
      "source": [
        "## Task 3: Training and evaluating your model (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RPoKiFckid9R"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate():\n",
        "    # TODO: Define the device (e.g., \"cuda\")\n",
        "    device = \"cuda\"\n",
        "\n",
        "    # Use the vocabulary built in the Data Preprocessing section.\n",
        "    vocab_size = len(vocab)\n",
        "    embed_dim = 100        # You can choose a value (e.g., 100)\n",
        "    hidden_dim = 128       # You can choose a value (e.g., 128)\n",
        "    output_dim = 1         # For binary classification, output dimension is 1\n",
        "    num_layers = 1         # Number of LSTM layers, e.g., 1\n",
        "    padding_idx = vocab['<pad>']\n",
        "\n",
        "    # TODO: Build your RNN classifier using your RNNClassifier class.\n",
        "    model = RNNClassifier(vocab_size, embed_dim, hidden_dim, output_dim, num_layers, padding_idx)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # TODO: Define your loss function\n",
        "    criterion = torch.nn.BCELoss()\n",
        "\n",
        "    # TODO: Define your optimizer with a chosen learning rate.\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Set the number of epochs for training.\n",
        "    num_epochs = 10  # You can adjust the number of epochs.\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # TODO: Set the model to training mode.\n",
        "        model.train()\n",
        "\n",
        "        epoch_loss = 0.0  # Initialize epoch loss.\n",
        "\n",
        "        # Iterate over batches in your training DataLoader.\n",
        "        for batch_idx, (text_batch, label_batch) in enumerate(train_loader):\n",
        "            # TODO: Move text_batch and label_batch to the defined device.\n",
        "            text_batch, label_batch = text_batch.to(device), label_batch.to(device)\n",
        "\n",
        "            # TODO: Zero out the gradients.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # TODO: Perform a forward pass: obtain predictions from the model.\n",
        "            predictions = model(text_batch)\n",
        "\n",
        "            # TODO: Compute the loss using your criterion.\n",
        "            loss = criterion(predictions, label_batch.float())\n",
        "\n",
        "            # TODO: Perform the backward pass to compute gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # TODO: Update the model parameters.\n",
        "            optimizer.step()\n",
        "\n",
        "            # TODO: Accumulate the loss for reporting.\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # Compute the average loss for the epoch and print it.\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # -------------------------\n",
        "    # Evaluation on Sample Yelp Reviews\n",
        "    # -------------------------\n",
        "\n",
        "    # Define some sample Yelp reviews for evaluation.\n",
        "    sample_reviews = [\n",
        "        \"The food was amazing and the service was excellent!\",\n",
        "        \"I did not enjoy my visit at all. The experience was terrible.\",\n",
        "        \"The ambiance was pleasant but the food was just okay.\",\n",
        "        \"Absolutely loved the place! Will come back again.\"\n",
        "    ]\n",
        "\n",
        "    # TODO: Set the model to evaluation mode.\n",
        "\n",
        "    predictions = []  # Store the predictions for the sample reviews.\n",
        "    print(\"Evaluation on Sample Yelp Reviews:\")\n",
        "    for review in sample_reviews:\n",
        "        with torch.no_grad():\n",
        "            # TODO: Convert the review text to a tensor using your text_pipeline function.\n",
        "            review_tensor = text_pipeline(review)\n",
        "            # TODO: Add a batch dimension to review_tensor (e.g., using unsqueeze).\n",
        "            review_tensor = torch.unsqueeze(review_tensor, 0)\n",
        "\n",
        "            # TODO: Move review_tensor to the device.\n",
        "            review_tensor = review_tensor.to(device)\n",
        "\n",
        "            # TODO: Perform a forward pass to get the prediction.\n",
        "            prediction = model(review_tensor)\n",
        "\n",
        "            # TODO: Interpret the prediction\n",
        "            sentiment = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
        "\n",
        "            # Print the review and its predicted sentiment along with the prediction score.\n",
        "            print(f\"Review: {review}\\nPredicted Sentiment: {sentiment} (Score: {prediction.item():.4f})\\n\")\n",
        "\n",
        "            # TODO: Append the prediction score (as a float) to the predictions list.\n",
        "            predictions.append(prediction.item())\n",
        "\n",
        "    # Return a dictionary with keys \"avg_loss\" and \"predictions\".\n",
        "    return {\"avg_loss\": avg_loss, \"predictions\": predictions}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate()"
      ],
      "metadata": {
        "id": "2d-6b_kWwI8W",
        "outputId": "1a43145c-04f8-4c6a-b8b4-8f31d382a06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "each element in list of batch should be of equal size",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-10f4fa97d095>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-532ddf57b868>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Iterate over batches in your training DataLoader.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;31m# TODO: Move text_batch and label_batch to the defined device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It may be accessed twice, so we use a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhWkiOwOid9R"
      },
      "source": [
        "## Task 4: Q&A Section (3 points)\n",
        "\n",
        "Please answer the questions below in brief. Each carries 1 point. This section is also open-book i.e., you can refer documentation to inform your response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zz7-YBBid9R"
      },
      "source": [
        "**Question 1:**  \n",
        "What is the purpose of specifying a `padding_idx` in the Embedding layer, and how does it affect the model's training and output?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "824zMKLmid9R"
      },
      "source": [
        "<font color='red'>*Your Answer:* </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI5ZU3s5id9R"
      },
      "source": [
        "> Since tokens are of different lengths, a padding is required to process words in batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VraiDqHid9R"
      },
      "source": [
        "**Question 2:**  \n",
        "Why do we use the final hidden state from the LSTM for classification? How does this hidden state encapsulate the overall information of the input sequence in the context of sentiment analysis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDytCa8Uid9R"
      },
      "source": [
        "<font color='red'>*Your Answer:* </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBd6Q7yCid9R"
      },
      "source": [
        "> We use the final hidden state to the LSTM for classification as"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JDzsIHCid9R"
      },
      "source": [
        "**Question 3:**  \n",
        "What is the role of the Sigmoid activation in this binary classification model? How might this change if you were working on a multi-class classification task? (think of other activation functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOWvg3coid9R"
      },
      "source": [
        "<font color='red'>*Your Answer:* </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-nTndo_id9S"
      },
      "source": [
        "> *(Type your answer here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ2ZtBcSid9S"
      },
      "source": [
        "---\n",
        "# Autograder section.\n",
        "\n",
        "After you finish your code implementation, please run this part of the notebook to see your score for the coding section (6 points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "ZJvvPEmWid9S",
        "outputId": "7d5fb6f6-6aa0-4d7b-e101-b96545b749af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preprocessing Test: Failed - label_pipeline should return an integer.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Module [RNNClassifier] is missing the required \"forward\" function",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-7afb5009628e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m# Run the custom test runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mrun_tests_and_accumulate_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-7afb5009628e>\u001b[0m in \u001b[0;36mrun_tests_and_accumulate_score\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# Test a forward pass using dummy input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Batch size of 4, sequence length of 10.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Expect output to be 1D with length equal to batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Output of forward pass should be 1D.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \"\"\"\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Module [{type(self).__name__}] is missing the required \\\"forward\\\" function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Module [RNNClassifier] is missing the required \"forward\" function"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# Pytest Code Cells for Evaluation\n",
        "# ================================\n",
        "\n",
        "def run_tests_and_accumulate_score():\n",
        "    score = 0\n",
        "    total = 6  # Total code points available: 2 + 2 + 2\n",
        "\n",
        "    # ------------------------------\n",
        "    # Part 1: Data Preprocessing (2 points)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        # Test that tokenizer is defined and callable.\n",
        "        assert tokenizer is not None, \"Tokenizer is not defined.\"\n",
        "        assert callable(tokenizer), \"Tokenizer is not callable.\"\n",
        "\n",
        "        # Test that yield_tokens is implemented.\n",
        "        assert callable(yield_tokens), \"yield_tokens function is not defined or callable.\"\n",
        "\n",
        "        # Test that train_list is loaded and non-empty.\n",
        "        assert len(train_list) > 0, \"train_list appears to be empty.\"\n",
        "\n",
        "        # Test that vocab is defined and includes the '<pad>' token.\n",
        "        assert vocab is not None, \"vocab is not defined.\"\n",
        "        itos = vocab.get_itos() if hasattr(vocab, \"get_itos\") else []\n",
        "        assert '<pad>' in itos, \"vocab does not contain the '<pad>' token.\"\n",
        "\n",
        "        # Test text_pipeline: it should return a list of integers.\n",
        "        sample_text = \"this is a test\"\n",
        "        token_ids = text_pipeline(sample_text)\n",
        "        assert isinstance(token_ids, list), \"text_pipeline should return a list.\"\n",
        "        for tid in token_ids:\n",
        "            assert isinstance(tid, int), \"Each token ID from text_pipeline should be an integer.\"\n",
        "\n",
        "        # Test label_pipeline: check that it converts labels (e.g., \"positive\") to an integer.\n",
        "        sample_label = \"positive\"\n",
        "        label_int = label_pipeline(sample_label)\n",
        "        assert isinstance(label_int, int), \"label_pipeline should return an integer.\"\n",
        "\n",
        "        # Optionally, test that the Dataset and DataLoader work.\n",
        "        dataset = YelpDataset(train_list)\n",
        "        # Ensure __len__ and __getitem__ work.\n",
        "        assert len(dataset) > 0, \"Dataset __len__ returned zero.\"\n",
        "        sample_item = dataset[0]\n",
        "        assert isinstance(sample_item, tuple) and len(sample_item) == 2, \"Dataset __getitem__ should return a tuple (text_tensor, label).\"\n",
        "        # Test collate_batch by creating a mini-batch.\n",
        "        batch = [dataset[i] for i in range(min(3, len(dataset)))]\n",
        "        collated = collate_batch(batch)\n",
        "        assert isinstance(collated, tuple) and len(collated) == 2, \"collate_batch should return a tuple (padded_texts, labels).\"\n",
        "\n",
        "        score += 2\n",
        "        print(\"Data Preprocessing Test: Passed (2 points)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"Data Preprocessing Test: Failed -\", e)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Part 2: RNN Implementation (2 points)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        # Use arbitrary parameters for testing.\n",
        "        test_vocab_size = 2000\n",
        "        test_embed_dim = 50\n",
        "        test_hidden_dim = 64\n",
        "        test_output_dim = 1\n",
        "        test_num_layers = 1\n",
        "        test_padding_idx = 0\n",
        "\n",
        "        model = RNNClassifier(test_vocab_size, test_embed_dim, test_hidden_dim, test_output_dim, test_num_layers, test_padding_idx)\n",
        "        assert isinstance(model, nn.Module), \"Model is not an instance of nn.Module.\"\n",
        "        # Verify required layers exist.\n",
        "        assert hasattr(model, \"embedding\"), \"Model is missing an embedding layer.\"\n",
        "        assert hasattr(model, \"lstm\"), \"Model is missing an LSTM layer.\"\n",
        "        assert hasattr(model, \"fc\"), \"Model is missing a fully connected layer.\"\n",
        "\n",
        "        # Test a forward pass using dummy input.\n",
        "        dummy_input = torch.randint(0, test_vocab_size, (4, 10))  # Batch size of 4, sequence length of 10.\n",
        "        output = model(dummy_input)\n",
        "        # Expect output to be 1D with length equal to batch size.\n",
        "        assert output.dim() == 1, \"Output of forward pass should be 1D.\"\n",
        "        assert output.shape[0] == 4, f\"Output batch size expected 4 but got {output.shape[0]}.\"\n",
        "\n",
        "        score += 2\n",
        "        print(\"RNN Implementation Test: Passed (2 points)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"RNN Implementation Test: Failed -\", e)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Part 3: Training & Evaluation (2 points)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        # Check that a function train_and_evaluate() is defined.\n",
        "        assert callable(train_and_evaluate), \"train_and_evaluate() function is not defined or callable.\"\n",
        "\n",
        "        # Call the function and capture its output.\n",
        "        results = train_and_evaluate()\n",
        "        # Expect results to be a dictionary containing at least 'predictions' and 'avg_loss'.\n",
        "        assert isinstance(results, dict), \"train_and_evaluate() should return a dictionary.\"\n",
        "        assert \"predictions\" in results, \"Results should contain the key 'predictions'.\"\n",
        "        assert \"avg_loss\" in results, \"Results should contain the key 'avg_loss'.\"\n",
        "        # Check that predictions is a list and contains 4 elements (one for each sample review).\n",
        "        predictions = results[\"predictions\"]\n",
        "        assert isinstance(predictions, list), \"'predictions' should be a list.\"\n",
        "        assert len(predictions) == 4, \"Expected 4 predictions for the sample reviews.\"\n",
        "\n",
        "        targetPreds = ['Positive', 'Negative', 'Negative', 'Positive']\n",
        "        for idx, pred in enumerate(predictions):\n",
        "            assert isinstance(pred, float), \"Each prediction should be a float.\"\n",
        "            assert 0.0 <= pred <= 1.0, \"Each prediction should be between 0 and 1.\"\n",
        "            sentiment = \"Positive\" if pred >= 0.5 else \"Negative\"\n",
        "            assert sentiment == targetPreds[idx], f\"Expected sentiment '{targetPreds[idx]}' but got '{sentiment}'.\"\n",
        "\n",
        "        score += 2\n",
        "        print(\"Training & Evaluation Test: Passed (2 points)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"Training & Evaluation Test: Failed -\", e)\n",
        "\n",
        "    print(f\"Total Code Score: {score} / {total}\")\n",
        "\n",
        "# Run the custom test runner\n",
        "run_tests_and_accumulate_score()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}